{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrian0s/ML4NLP1-2025-Tutorial-Notebooks/blob/main/exercises/ex4/ex4_ner_bert_given_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBK3YDwgVBjN"
      },
      "source": [
        "# Load and prepare the required data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqqgMPaTyVsT",
        "outputId": "9f08e9f1-7954-4de6-8e4f-49fb2cfd0b1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in ./.venv312/lib64/python3.12/site-packages (4.4.1)\n",
            "Requirement already satisfied: filelock in ./.venv312/lib64/python3.12/site-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv312/lib64/python3.12/site-packages (from datasets) (2.3.4)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in ./.venv312/lib64/python3.12/site-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.venv312/lib64/python3.12/site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in ./.venv312/lib64/python3.12/site-packages (from datasets) (2.3.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./.venv312/lib64/python3.12/site-packages (from datasets) (2.32.5)\n",
            "Requirement already satisfied: httpx<1.0.0 in ./.venv312/lib64/python3.12/site-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in ./.venv312/lib64/python3.12/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in ./.venv312/lib64/python3.12/site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in ./.venv312/lib64/python3.12/site-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in ./.venv312/lib64/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.9.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in ./.venv312/lib64/python3.12/site-packages (from datasets) (0.25.2)\n",
            "Requirement already satisfied: packaging in ./.venv312/lib64/python3.12/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv312/lib64/python3.12/site-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv312/lib64/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in ./.venv312/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in ./.venv312/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv312/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in ./.venv312/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in ./.venv312/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv312/lib64/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv312/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv312/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv312/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv312/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv312/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.venv312/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv312/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv312/lib64/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv312/lib64/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./.venv312/lib64/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv312/lib64/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv312/lib64/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv312/lib64/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv312/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-WV5IWPkxmjo"
      },
      "outputs": [],
      "source": [
        "# Choose a supported language, apart from English. Examples: \"de\", \"fr\", \"es\", \"it\".\n",
        "# NOTE: See dataset card for supported languages (https://huggingface.co/datasets/unimelb-nlp/wikiann)\n",
        "chosen_language_code = \"de\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ggqfgV_nO5Qj"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "\n",
        "# NOTE: If the maximum sequence length exceeds the model's maximum\n",
        "# sequence length, you need to make adjustments (for example, when\n",
        "# choosing 'en')\n",
        "test_set = datasets.load_dataset(\"unimelb-nlp/wikiann\", chosen_language_code, split=\"test[:2000]\")\n",
        "train_set1000 = datasets.load_dataset(\"unimelb-nlp/wikiann\", chosen_language_code, split=\"train[:1000]\")\n",
        "train_set3000 = datasets.load_dataset(\"unimelb-nlp/wikiann\", chosen_language_code, split=\"train[:3000]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNYxEU3YO5Ql"
      },
      "source": [
        "**NOTE: Make sure that there are indeed as many data points in the above sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IMFy3wCLO5Qm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
            "    num_rows: 1000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
            "    num_rows: 3000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
            "    num_rows: 2000\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(train_set1000)\n",
        "print(train_set3000)\n",
        "print(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N0wMdjnvO5Qn"
      },
      "outputs": [],
      "source": [
        "ner_tags = {\n",
        "    \"O\": 0,\n",
        "    \"B-PER\": 1,\n",
        "    \"I-PER\": 2,\n",
        "    \"B-ORG\": 3,\n",
        "    \"I-ORG\": 4,\n",
        "    \"B-LOC\": 5,\n",
        "    \"I-LOC\": 6\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ArOWU99T58D"
      },
      "source": [
        "**TODO: Inspect and Describe the Data, including Average and Maximum Input length (in tokens)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfyYXRLoU6mV"
      },
      "source": [
        "üìù‚ùìWhy do you need to be aware of the longest input length within your dataset? Which parameter of the model dictates this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transformers: 4.41.1\n",
            "huggingface_hub: 0.25.2\n"
          ]
        }
      ],
      "source": [
        "import transformers, huggingface_hub\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "print(\"huggingface_hub:\", huggingface_hub.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5KxkH5vBO5Qw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer loaded!\n",
            "Vocabulary size: 30000\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# TODO: Load the tokenizer\n",
        "model_name = \"google-bert/bert-base-german-cased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "print(\"Tokenizer loaded!\")\n",
        "print(\"Vocabulary size:\", tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "114\n"
          ]
        }
      ],
      "source": [
        "# find true max tokenized length (incl. special tokens), then clamp to model limit\n",
        "def longest_tokenized_len(ds, tok):\n",
        "    m = 0\n",
        "    for ex in ds:\n",
        "        enc = tok(\n",
        "            ex[\"tokens\"],\n",
        "            is_split_into_words=True,\n",
        "            add_special_tokens=True,\n",
        "            padding=False,\n",
        "            truncation=False,\n",
        "        )\n",
        "        m = max(m, len(enc[\"input_ids\"]))\n",
        "    return m\n",
        "\n",
        "max_sequence_length = min(\n",
        "    max(\n",
        "        longest_tokenized_len(train_set1000, tokenizer),\n",
        "        longest_tokenized_len(train_set3000, tokenizer),\n",
        "        longest_tokenized_len(test_set, tokenizer)\n",
        "    ),\n",
        "    int(getattr(tokenizer, \"model_max_length\", 512)),\n",
        ")\n",
        "print(max_sequence_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n-1XQS_M2WO2"
      },
      "outputs": [],
      "source": [
        "# TODO: Adjust by actually finding the maximum sequence length\n",
        "max_sequence_length = 114"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "idpa54l4O5Qv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "114\n"
          ]
        }
      ],
      "source": [
        "print(max_sequence_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2qFayooO5Qx"
      },
      "source": [
        "üìù‚ùìThe dataset is split into words, and the assigned labels are for words. How should we deal with labels **after** tokenization? NOTE: Each word may be split into one or multiple tokens by the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mvc66dR9x6Fe"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement this function\n",
        "def encode_and_align_labels(dataset, tokenizer, max_sequence_length):\n",
        "    \"\"\"Tokenizes the input tokens and aligns the word-level NER labels with the tokenized output.\"\"\"\n",
        "    # policy: only the first sub-token gets the word's label; others -> -100\n",
        "    label_all_tokens = False\n",
        "\n",
        "    if not getattr(tokenizer, \"is_fast\", False):\n",
        "        raise ValueError(\n",
        "            \"This function requires a *fast* tokenizer (tokenizers library) \"\n",
        "            \"because it uses `word_ids()` to align labels.\"\n",
        "        )\n",
        "\n",
        "    def _process(example):\n",
        "        # example[\"tokens\"] is a list[str], example[\"ner_tags\"] is a list[int] (one per word)\n",
        "        enc = tokenizer(\n",
        "            example[\"tokens\"],\n",
        "            is_split_into_words=True,\n",
        "            truncation=True,\n",
        "            max_length=max_sequence_length,\n",
        "            padding=\"max_length\",\n",
        "            return_attention_mask=True,\n",
        "        )\n",
        "\n",
        "        word_ids = enc.word_ids()  # len == max_sequence_length (after padding)\n",
        "        labels = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                # special token (CLS/SEP/PAD) -> ignore in loss\n",
        "                labels.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # first token of a word -> take that word's label\n",
        "                labels.append(example[\"ner_tags\"][word_idx])\n",
        "            else:\n",
        "                # subsequent sub-token of the same word\n",
        "                if label_all_tokens:\n",
        "                    labels.append(example[\"ner_tags\"][word_idx])\n",
        "                else:\n",
        "                    labels.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        enc[\"labels\"] = labels\n",
        "        return enc\n",
        "\n",
        "    # map over the whole dataset; remove original columns to keep only model inputs\n",
        "    cols_to_remove = [c for c in dataset.column_names if c not in (\"id\",)]\n",
        "    tokenized = dataset.map(_process, remove_columns=cols_to_remove)\n",
        "    return tokenized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_0zufGtNw6yk"
      },
      "outputs": [],
      "source": [
        "# TODO: Encode the two training sets and the test set by applying the function above\n",
        "encoded_test_set = encode_and_align_labels(test_set,tokenizer,max_sequence_length)\n",
        "encoded_train_set1000 = encode_and_align_labels(train_set1000,tokenizer,max_sequence_length)\n",
        "encoded_train_set3000 = encode_and_align_labels(train_set3000,tokenizer,max_sequence_length)\n",
        "\n",
        "\n",
        "\n",
        "# Set format for PyTorch\n",
        "encoded_test_set.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
        ")\n",
        "encoded_train_set1000.set_format(\n",
        "\ttype=\"torch\",\n",
        "\tcolumns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
        ")\n",
        "encoded_train_set3000.set_format(\n",
        "\ttype=\"torch\",\n",
        "\tcolumns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oykr25qgnBOg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4900/1694782954.py:5: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
            "  labels = np.concatenate([np.array(x[\"labels\"]) for x in ds])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train1000 labels: {'total_tokens': 114000, 'ignored_-100': 104233, 'ignored_%': 91.43245614035088, 'num_labeled_tokens': 9767, 'min_label_id': 0, 'max_label_id': 6}\n",
            "train3000 labels: {'total_tokens': 342000, 'ignored_-100': 312784, 'ignored_%': 91.45730994152046, 'num_labeled_tokens': 29216, 'min_label_id': 0, 'max_label_id': 6}\n",
            "test labels: {'total_tokens': 228000, 'ignored_-100': 208735, 'ignored_%': 91.55043859649122, 'num_labeled_tokens': 19265, 'min_label_id': 0, 'max_label_id': 6}\n",
            "\n",
            "train1000[0]\n",
            "input_ids: (114,)\n",
            "attention_mask: (114,)\n",
            "labels: (114,)\n",
            "\n",
            "train3000[0]\n",
            "input_ids: (114,)\n",
            "attention_mask: (114,)\n",
            "labels: (114,)\n",
            "\n",
            "test[0]\n",
            "input_ids: (114,)\n",
            "attention_mask: (114,)\n",
            "labels: (114,)\n",
            "train1000 specials: {'special_tokens_with_non_ignored_labels': 0, 'checked_pairs': 114000}\n",
            "train3000 specials: {'special_tokens_with_non_ignored_labels': 0, 'checked_pairs': 342000}\n",
            "test specials: {'special_tokens_with_non_ignored_labels': 0, 'checked_pairs': 228000}\n"
          ]
        }
      ],
      "source": [
        "# Check out how the training sets are encoded\n",
        "import numpy as np\n",
        "\n",
        "def label_stats(ds):\n",
        "    labels = np.concatenate([np.array(x[\"labels\"]) for x in ds])\n",
        "    return {\n",
        "        \"total_tokens\": int(labels.size),\n",
        "        \"ignored_-100\": int((labels == -100).sum()),\n",
        "        \"ignored_%\":    float((labels == -100).mean() * 100),\n",
        "        \"num_labeled_tokens\": int((labels != -100).sum()),\n",
        "        \"min_label_id\": int(labels[labels != -100].min()) if (labels != -100).any() else None,\n",
        "        \"max_label_id\": int(labels[labels != -100].max()) if (labels != -100).any() else None,\n",
        "    }\n",
        "\n",
        "print(\"train1000 labels:\", label_stats(encoded_train_set1000))\n",
        "print(\"train3000 labels:\", label_stats(encoded_train_set3000))\n",
        "print(\"test labels:\",      label_stats(encoded_test_set))\n",
        "\n",
        "def show_shapes(ds, name):\n",
        "    print(f\"\\n{name}\")\n",
        "    ex = ds[0]\n",
        "    for k, v in ex.items():\n",
        "        if hasattr(v, \"size\"):\n",
        "            print(f\"{k}: {tuple(v.size())}\")\n",
        "        else:\n",
        "            print(f\"{k}: (scalar or list) -> {type(v)}\")\n",
        "\n",
        "show_shapes(encoded_train_set1000, \"train1000[0]\")\n",
        "show_shapes(encoded_train_set3000, \"train3000[0]\")\n",
        "show_shapes(encoded_test_set,      \"test[0]\")\n",
        "\n",
        "def special_token_label_check(ds, tokenizer):\n",
        "    cls_id = tokenizer.cls_token_id\n",
        "    sep_id = tokenizer.sep_token_id\n",
        "    pad_id = tokenizer.pad_token_id\n",
        "    bad = 0\n",
        "    total = 0\n",
        "    for row in ds:\n",
        "        ids = row[\"input_ids\"]\n",
        "        labs = row[\"labels\"]\n",
        "        for tid, lab in zip(ids, labs):\n",
        "            if tid in (cls_id, sep_id, pad_id) and lab != -100:\n",
        "                bad += 1\n",
        "            total += 1\n",
        "    return {\"special_tokens_with_non_ignored_labels\": bad, \"checked_pairs\": total}\n",
        "\n",
        "print(\"train1000 specials:\", special_token_label_check(encoded_train_set1000, tokenizer))\n",
        "print(\"train3000 specials:\", special_token_label_check(encoded_train_set3000, tokenizer))\n",
        "print(\"test specials:\",      special_token_label_check(encoded_test_set,      tokenizer))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEJXYvbOa-E4"
      },
      "source": [
        "Example of how your output could look like.\n",
        "\n",
        "input_ids: torch.Size([???])\n",
        "\n",
        "token_type_ids: torch.Size([???])\n",
        "\n",
        "attention_mask: torch.Size([???])\n",
        "\n",
        "labels: torch.Size([???])\n",
        "\n",
        "üìù‚ùìWhat value should replace the three question marks in your print? Should this be the sample for all samples? Why/Why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnWH-MaKO5Q1"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdIPhpLiO5Q1"
      },
      "source": [
        "## Training Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sy2LxB_2O5Q2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSpxJMtkO5Q3"
      },
      "source": [
        "**TODO: Complete the following, reusable functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gKhJH6wQO5Q4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(preds):\n",
        "    \"\"\"\n",
        "    Compute macro and micro F1 scores from PredictionOutput\n",
        "\n",
        "    Args:\n",
        "        preds: transformers.trainer_utils.PredictionOutput\n",
        "\n",
        "    Returns:\n",
        "        dict with macro_f1 and micro_f1 scores\n",
        "    \"\"\"\n",
        "        # Get model predictions and true labels\n",
        "    logits = preds.predictions\n",
        "    labels = preds.label_ids\n",
        "\n",
        "    # Take argmax over last dimension for predicted class indices\n",
        "    pred_labels = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Mask out ignored positions (-100)\n",
        "    mask = labels != -100\n",
        "    true = labels[mask]\n",
        "    pred = pred_labels[mask]\n",
        "\n",
        "    # Compute F1 scores\n",
        "    macro_f1 = f1_score(true, pred, average=\"macro\")\n",
        "    micro_f1 = f1_score(true, pred, average=\"micro\")\n",
        "\n",
        "    return {\"macro_f1\": macro_f1, \"micro_f1\": micro_f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ePcLuf4QO5Q4"
      },
      "outputs": [],
      "source": [
        "def freeze_weights(model):\n",
        "    \"\"\"Freeze the weights for a given model.\n",
        "\n",
        "    Args:\n",
        "        model: transformers.PreTrainedModel\n",
        "\n",
        "    Returns:\n",
        "\t\t\tmodel: transformers.PreTrainedModel\n",
        "    \"\"\"\n",
        "\n",
        "        # Freeze all parameters\n",
        "    for param in model.base_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Unfreeze classifier head if it exists\n",
        "    if hasattr(model, \"classifier\"):\n",
        "        print(\"has head if\")\n",
        "        for param in model.classifier.parameters():\n",
        "            param.requires_grad = True\n",
        "    elif hasattr(model, \"score\"):\n",
        "        print(\"has head elif\")\n",
        "        for param in model.score.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cevovk8ZO5Q5"
      },
      "source": [
        "## Variation 1: 1000 sentences, no frozen weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru--p5NZO5Q6"
      },
      "source": [
        "**TODO: Initialise your model and set up your training arguments**\n",
        "\n",
        "üìù‚ùìWhen initializing the BertForTokenClassification-class with BERT-base you should get a warning message. Explain why you get this message.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JD72g8GC2Rwx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification, Trainer, TrainingArguments\n",
        "\n",
        "model_name = \"google-bert/bert-base-german-cased\"\n",
        "\n",
        "# Infer number of labels from the dataset\n",
        "num_labels = 7\n",
        "id2label = {i: str(i) for i in range(num_labels)}\n",
        "label2id = {str(i): i for i in range(num_labels)}\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "# Variation 1: 1000 sentences, no frozen weights\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./tmp_checkpoints\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_train_set1000,\n",
        "    eval_dataset=encoded_test_set,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_DBflx1wzRa"
      },
      "source": [
        "**TODO: Train your Model ‚ö° GPU 2-3 mins**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z3XEgVHrxJTq"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11bd52d83364459c9b29e9bcf5de04b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/189 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5769, 'grad_norm': 3.935152292251587, 'learning_rate': 3.677248677248677e-05, 'epoch': 0.79}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e865c02c13954fac9d28ad2fc6113af9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2420370876789093, 'eval_macro_f1': 0.819819357094382, 'eval_micro_f1': 0.928834674279782, 'eval_runtime': 109.0666, 'eval_samples_per_second': 18.337, 'eval_steps_per_second': 1.146, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.201, 'grad_norm': 5.456484317779541, 'learning_rate': 2.3544973544973546e-05, 'epoch': 1.59}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bc50c98fa5b4e6caa7c3ecba1f78f99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.22543145716190338, 'eval_macro_f1': 0.8435660735094731, 'eval_micro_f1': 0.9352193096288606, 'eval_runtime': 102.8721, 'eval_samples_per_second': 19.442, 'eval_steps_per_second': 1.215, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1164, 'grad_norm': 1.355809211730957, 'learning_rate': 1.0317460317460318e-05, 'epoch': 2.38}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1abf2dc57634dcebf6ca81e4ed27134",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.22160883247852325, 'eval_macro_f1': 0.8521901116758004, 'eval_micro_f1': 0.9400986244484817, 'eval_runtime': 102.2606, 'eval_samples_per_second': 19.558, 'eval_steps_per_second': 1.222, 'epoch': 3.0}\n",
            "{'train_runtime': 1014.4413, 'train_samples_per_second': 2.957, 'train_steps_per_second': 0.186, 'train_loss': 0.25023620216934767, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./bert-german-var1-1000-no-freeze-best/tokenizer_config.json',\n",
              " './bert-german-var1-1000-no-freeze-best/special_tokens_map.json',\n",
              " './bert-german-var1-1000-no-freeze-best/vocab.txt',\n",
              " './bert-german-var1-1000-no-freeze-best/added_tokens.json',\n",
              " './bert-german-var1-1000-no-freeze-best/tokenizer.json')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()\n",
        "save_path = \"./bert-german-var1-1000-no-freeze-best\"\n",
        "\n",
        "trainer.save_model(save_path)   \n",
        "tokenizer.save_pretrained(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt86VaDIiMWd"
      },
      "source": [
        "**TODO: Compute Metrics/Performance of your model.**\n",
        "\n",
        "üìù‚ùì Is there a challenge when evaluating the predictions of your model? Why is this challenge present and how do you plan to deal with it?\n",
        "\n",
        "Hint: Look at the lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ryi-Vnrw7NJ"
      },
      "source": [
        "To avoid rerunning, please also print the metrics of each model that completed training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_nE3HeKW4TFl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1b968ae53d7476eafee004629037d8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1: 0.8521901116758004\n",
            "Micro F1: 0.9400986244484817\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation with the trained model\n",
        "preds = trainer.predict(encoded_test_set)\n",
        "\n",
        "# Compute metrics using your function\n",
        "metrics = compute_metrics(preds)\n",
        "\n",
        "# Print nicely\n",
        "print(\"Macro F1:\", metrics[\"macro_f1\"])\n",
        "print(\"Micro F1:\", metrics[\"micro_f1\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AKh4cXm7F8R"
      },
      "source": [
        "## Variant 2: 3000 sentences, no frozen weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HHmo4lCp2Bj7"
      },
      "outputs": [],
      "source": [
        "# Repeat after each run to save VRAM\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# New model instance\n",
        "model2 = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "# TrainingArguments for the 3000-sentence run\n",
        "training_args2 = TrainingArguments(\n",
        "    output_dir=\"./tmp_checkpoints_3000\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "# Trainer for the 3000-sentence experiment\n",
        "trainer2 = Trainer(\n",
        "    model=model2,\n",
        "    args=training_args2,\n",
        "    train_dataset=encoded_train_set3000,\n",
        "    eval_dataset=encoded_test_set,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be0d7a543b8e481ba1ddac5f543bdc04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/564 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5361, 'grad_norm': 1.3793773651123047, 'learning_rate': 4.556737588652483e-05, 'epoch': 0.27}\n",
            "{'loss': 0.2555, 'grad_norm': 3.372178792953491, 'learning_rate': 4.1134751773049644e-05, 'epoch': 0.53}\n",
            "{'loss': 0.2286, 'grad_norm': 4.001646041870117, 'learning_rate': 3.670212765957447e-05, 'epoch': 0.8}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fb55fa039bd4a06840e995775a1e8a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.1834031641483307, 'eval_macro_f1': 0.8634586120738128, 'eval_micro_f1': 0.9450817544770309, 'eval_runtime': 104.4867, 'eval_samples_per_second': 19.141, 'eval_steps_per_second': 1.196, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.1943, 'grad_norm': 4.347424507141113, 'learning_rate': 3.226950354609929e-05, 'epoch': 1.06}\n",
            "{'loss': 0.1153, 'grad_norm': 5.694786548614502, 'learning_rate': 2.7836879432624114e-05, 'epoch': 1.33}\n",
            "{'loss': 0.0859, 'grad_norm': 13.40363597869873, 'learning_rate': 2.340425531914894e-05, 'epoch': 1.6}\n",
            "{'loss': 0.1191, 'grad_norm': 1.5239781141281128, 'learning_rate': 1.897163120567376e-05, 'epoch': 1.86}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b301e7431314fe0bc213e4e91dbc0a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.1795254796743393, 'eval_macro_f1': 0.8679062701776432, 'eval_micro_f1': 0.9487671943939787, 'eval_runtime': 105.3173, 'eval_samples_per_second': 18.99, 'eval_steps_per_second': 1.187, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0937, 'grad_norm': 1.7093050479888916, 'learning_rate': 1.4539007092198581e-05, 'epoch': 2.13}\n",
            "{'loss': 0.0518, 'grad_norm': 2.692333698272705, 'learning_rate': 1.0106382978723404e-05, 'epoch': 2.39}\n",
            "{'loss': 0.0439, 'grad_norm': 1.697993278503418, 'learning_rate': 5.673758865248227e-06, 'epoch': 2.66}\n",
            "{'loss': 0.0475, 'grad_norm': 0.32915547490119934, 'learning_rate': 1.2411347517730497e-06, 'epoch': 2.93}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04b79aa489a145d9a4fb9049a71a1898",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.19612905383110046, 'eval_macro_f1': 0.8761339629592192, 'eval_micro_f1': 0.951881650661822, 'eval_runtime': 101.9673, 'eval_samples_per_second': 19.614, 'eval_steps_per_second': 1.226, 'epoch': 3.0}\n",
            "{'train_runtime': 2437.954, 'train_samples_per_second': 3.692, 'train_steps_per_second': 0.231, 'train_loss': 0.15781137785801652, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./bert-german-var2-3000-no-freeze-best/tokenizer_config.json',\n",
              " './bert-german-var2-3000-no-freeze-best/special_tokens_map.json',\n",
              " './bert-german-var2-3000-no-freeze-best/vocab.txt',\n",
              " './bert-german-var2-3000-no-freeze-best/added_tokens.json',\n",
              " './bert-german-var2-3000-no-freeze-best/tokenizer.json')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "trainer2.train()\n",
        "\n",
        "# Save best model\n",
        "save_path = \"./bert-german-var2-3000-no-freeze-best\"\n",
        "trainer2.save_model(save_path)\n",
        "tokenizer.save_pretrained(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78354996b84f4879b667bbabbc4f08ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1: 0.8761339629592192\n",
            "Micro F1: 0.951881650661822\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation with the trained model\n",
        "preds = trainer2.predict(encoded_test_set)\n",
        "\n",
        "# Compute metrics using your function\n",
        "metrics = compute_metrics(preds)\n",
        "\n",
        "# Print nicely\n",
        "print(\"Macro F1:\", metrics[\"macro_f1\"])\n",
        "print(\"Micro F1:\", metrics[\"micro_f1\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsU1E0_p7ITW"
      },
      "source": [
        "## Variant 3: 1000 sentences, frozen weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FTXRQCgz7Vcu"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification, Trainer, TrainingArguments\n",
        "\n",
        "model_name = \"google-bert/bert-base-german-cased\"\n",
        "\n",
        "num_labels = 7\n",
        "id2label = {i: str(i) for i in range(num_labels)}\n",
        "label2id = {str(i): i for i in range(num_labels)}\n",
        "\n",
        "model3 = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "# freeze all parameters except the token classification head\n",
        "for name, param in model.named_parameters():\n",
        "    if not name.startswith(\"classifier.\"):\n",
        "        param.requires_grad = False\n",
        "\n",
        "training_args3 = TrainingArguments(\n",
        "    output_dir=\"./tmp_checkpoints\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-4,  # often higher lr when only the head is trained\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.0,    # usually not needed when training only the head\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "trainer3 = Trainer(\n",
        "    model=model,\n",
        "    args=training_args3,\n",
        "    train_dataset=encoded_train_set1000,\n",
        "    eval_dataset=encoded_test_set,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c72412cbfc8442a7b9222a385550db27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/189 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0302, 'grad_norm': 0.1491064876317978, 'learning_rate': 0.00036772486772486775, 'epoch': 0.79}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50292278f54246e881bddb3cd807a4f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.24064382910728455, 'eval_macro_f1': 0.8525059130657553, 'eval_micro_f1': 0.9402543472618738, 'eval_runtime': 102.6177, 'eval_samples_per_second': 19.49, 'eval_steps_per_second': 1.218, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0243, 'grad_norm': 0.42833206057548523, 'learning_rate': 0.00023544973544973544, 'epoch': 1.59}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b74202fe2eb49fc82810093b6023a4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.24750985205173492, 'eval_macro_f1': 0.8533094107997939, 'eval_micro_f1': 0.94046197767973, 'eval_runtime': 98.9588, 'eval_samples_per_second': 20.21, 'eval_steps_per_second': 1.263, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0234, 'grad_norm': 0.18955840170383453, 'learning_rate': 0.00010317460317460317, 'epoch': 2.38}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a43fd744cf014404a9d06ce96efef212",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2491428256034851, 'eval_macro_f1': 0.8539203418465491, 'eval_micro_f1': 0.9405657928886582, 'eval_runtime': 102.3246, 'eval_samples_per_second': 19.546, 'eval_steps_per_second': 1.222, 'epoch': 3.0}\n",
            "{'train_runtime': 574.3007, 'train_samples_per_second': 5.224, 'train_steps_per_second': 0.329, 'train_loss': 0.027942722436612246, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./bert-german-var2-3000-no-freeze-best/tokenizer_config.json',\n",
              " './bert-german-var2-3000-no-freeze-best/special_tokens_map.json',\n",
              " './bert-german-var2-3000-no-freeze-best/vocab.txt',\n",
              " './bert-german-var2-3000-no-freeze-best/added_tokens.json',\n",
              " './bert-german-var2-3000-no-freeze-best/tokenizer.json')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "trainer3.train()\n",
        "\n",
        "# Save best model\n",
        "save_path = \"./bert-german-var2-3000-no-freeze-best\"\n",
        "trainer2.save_model(save_path)\n",
        "tokenizer.save_pretrained(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b1fb772f79045a4a5b05a9b68588315",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1: 0.8539203418465491\n",
            "Micro F1: 0.9405657928886582\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation with the trained model\n",
        "preds = trainer3.predict(encoded_test_set)\n",
        "\n",
        "# Compute metrics using your function\n",
        "metrics = compute_metrics(preds)\n",
        "\n",
        "# Print nicely\n",
        "print(\"Macro F1:\", metrics[\"macro_f1\"])\n",
        "print(\"Micro F1:\", metrics[\"micro_f1\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6wE6mAm7y7m"
      },
      "source": [
        "## Variant 4: 3000 sentences, frozen weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RxkAuigt7y7n"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# New model instance\n",
        "model4 = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "# freeze encoder parameters\n",
        "for name, param in model2.named_parameters():\n",
        "    if not name.startswith(\"classifier.\"):\n",
        "        param.requires_grad = False\n",
        "\n",
        "# TrainingArguments for the 3000-sentence run\n",
        "training_args4 = TrainingArguments(\n",
        "    output_dir=\"./tmp_checkpoints_3000\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-4,   # optional: head-only training usually needs higher lr\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.0,     # optional: no need for decay when only head trains\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "# Trainer for the 3000-sentence experiment\n",
        "trainer4 = Trainer(\n",
        "    model=model2,\n",
        "    args=training_args4,\n",
        "    train_dataset=encoded_train_set3000,\n",
        "    eval_dataset=encoded_test_set,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfe2de42b6c14f6e95758f7d4c79f4fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/564 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.025, 'grad_norm': 0.04806634411215782, 'learning_rate': 0.0004556737588652483, 'epoch': 0.27}\n",
            "{'loss': 0.0175, 'grad_norm': 0.014092344790697098, 'learning_rate': 0.00041134751773049644, 'epoch': 0.53}\n",
            "{'loss': 0.0151, 'grad_norm': 0.20460699498653412, 'learning_rate': 0.0003670212765957447, 'epoch': 0.8}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e826567e78b462fb146814f64399af5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2263677716255188, 'eval_macro_f1': 0.8758220021791596, 'eval_micro_f1': 0.951933558266286, 'eval_runtime': 101.728, 'eval_samples_per_second': 19.66, 'eval_steps_per_second': 1.229, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0164, 'grad_norm': 0.43018898367881775, 'learning_rate': 0.00032269503546099293, 'epoch': 1.06}\n",
            "{'loss': 0.0176, 'grad_norm': 0.07015915215015411, 'learning_rate': 0.00027836879432624115, 'epoch': 1.33}\n",
            "{'loss': 0.0116, 'grad_norm': 0.2467830777168274, 'learning_rate': 0.00023404255319148937, 'epoch': 1.6}\n",
            "{'loss': 0.0149, 'grad_norm': 0.019283650442957878, 'learning_rate': 0.00018971631205673758, 'epoch': 1.86}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e620772ae17456eb8a63027800bf6ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.22908951342105865, 'eval_macro_f1': 0.8786254224394601, 'eval_micro_f1': 0.9525564495198546, 'eval_runtime': 103.6011, 'eval_samples_per_second': 19.305, 'eval_steps_per_second': 1.207, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.0143, 'grad_norm': 0.016608374193310738, 'learning_rate': 0.0001453900709219858, 'epoch': 2.13}\n",
            "{'loss': 0.0118, 'grad_norm': 0.06037967652082443, 'learning_rate': 0.00010106382978723403, 'epoch': 2.39}\n",
            "{'loss': 0.0104, 'grad_norm': 0.25608113408088684, 'learning_rate': 5.673758865248227e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0199, 'grad_norm': 0.046331048011779785, 'learning_rate': 1.2411347517730498e-05, 'epoch': 2.93}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97608cb5eef94f51a4b67a6850f65c34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.23117201030254364, 'eval_macro_f1': 0.8784029779983585, 'eval_micro_f1': 0.9525564495198546, 'eval_runtime': 104.8084, 'eval_samples_per_second': 19.082, 'eval_steps_per_second': 1.193, 'epoch': 3.0}\n",
            "{'train_runtime': 1122.9605, 'train_samples_per_second': 8.015, 'train_steps_per_second': 0.502, 'train_loss': 0.016136933303048426, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./bert-german-var2-3000-no-freeze-best/tokenizer_config.json',\n",
              " './bert-german-var2-3000-no-freeze-best/special_tokens_map.json',\n",
              " './bert-german-var2-3000-no-freeze-best/vocab.txt',\n",
              " './bert-german-var2-3000-no-freeze-best/added_tokens.json',\n",
              " './bert-german-var2-3000-no-freeze-best/tokenizer.json')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "trainer4.train()\n",
        "\n",
        "# Save best model\n",
        "save_path = \"./bert-german-var2-3000-no-freeze-best\"\n",
        "trainer2.save_model(save_path)\n",
        "tokenizer.save_pretrained(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/work/Documents/GitHub/ML4NLP1/exercises/ex4/.venv312/lib64/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e94640fadb246569ef4a5868bfda131",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1: 0.8786254224394601\n",
            "Micro F1: 0.9525564495198546\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation with the trained model\n",
        "preds = trainer4.predict(encoded_test_set)\n",
        "\n",
        "# Compute metrics using your function\n",
        "metrics = compute_metrics(preds)\n",
        "\n",
        "# Print nicely\n",
        "print(\"Macro F1:\", metrics[\"macro_f1\"])\n",
        "print(\"Micro F1:\", metrics[\"micro_f1\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iTcwgmtO5Q_"
      },
      "source": [
        "# Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2LyNOP6oVsz"
      },
      "source": [
        "üìù‚ùì Template:\n",
        "\n",
        "Summary of Performance of the four Model Variants\n",
        "\n",
        "1. Whole Model finetuning, 1000 samples:\n",
        "2. Whole Model finetuning, 3000 samples:\n",
        "3. Frozen Backbone, 1000 samples:\n",
        "4. Frozen Backbone 3000 samples:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPi_aox2O5RA"
      },
      "source": [
        "üìù‚ùì When we freeze the transformer backbone weights, which weights are being tuned during fine-tuning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR2j40qivASb"
      },
      "source": [
        "üìù‚ùì Are there differences between f1-micro and f1-macro score? If so, why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqyOEWsr-J4s"
      },
      "source": [
        "üìù‚ùì Is it better to freeze or not to freeze the transformer backbone weights? Hypothesize why"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBCHlRNgxPTn"
      },
      "source": [
        "\n",
        "\n",
        "üìù‚ùì Write your lab report here addressing all questions in the notebook"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
